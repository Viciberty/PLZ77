%Title
%!TEX program = xelatex
%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------
\documentclass[letterpaper,12pt]{article}
%Graph
\usepackage{tabularx} % extra features for tabular environment
\usepackage{amsmath}  % improve math presentation
\usepackage{graphicx} % takes care of graphic including machinery
\usepackage[margin=1in,letterpaper]{geometry} % decreases margins
\usepackage{cite} % takes care of citations
\usepackage[final]{hyperref} % adds hyper links inside the generated pdf file
    \hypersetup{
	    colorlinks=true,       % false: boxed links; true: colored links
	    linkcolor=blue,        % color of internal links
	    citecolor=blue,        % color of links to bibliography
	    filecolor=magenta,     % color of file links
	    urlcolor=blue         
    }    
%Font
\usepackage{xeCJK,indentfirst}         %中文包&XeLaTex
    \setCJKmainfont[BoldFont=STZhongsong, ItalicFont=STKaiti]{STSong}
    \setCJKsansfont[BoldFont=STHeiti]{STXihei}
    \setCJKmonofont{STFangsong}
\usepackage{fontspec}
    \setmainfont{Times New Roman}
    \setsansfont{Arial}
%Picture

\usepackage{tikz}
    \usetikzlibrary{arrows}
\usepackage{asymptote}
\usepackage{algorithm}  
\usepackage{algpseudocode}  
\usepackage{amsmath}  
\renewcommand{\algorithmicrequire}{\textbf{Input:}}  % Use Input in the format of Algorithm  
\renewcommand{\algorithmicensure}{\textbf{Output:}} % Use Output in the format of Algorithm 
%Algorithm

\begin{document}
%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------
\title{Solutions}
\author{Ruipeng Li, School of Physics}
\date{\today}
\maketitle
%----------------------------------------------------------------------------------------
%	ABSTRACT SECTION
%----------------------------------------------------------------------------------------
\begin{abstract}	
Problem1 Multi-armed Bandit Problem\par
Problem2 Bike sharing economy\par
\end{abstract}
%----------------------------------------------------------------------------------------
%   TEXT SECTION
%----------------------------------------------------------------------------------------
\begin{section}{Problem1 UCB Alogrithm with prior knowledge}
    \begin{subsection}{Problem Description}
        Assume there are K gambling machines marked by random variables $X_{i,n}$ for $1 \le i \le K$ and $n \ge 1$. Successive plays of machine i yield rewards $X_{i,1},X_{i,2},\cdots$which are iid according to an unknown law wtih unknown expectation $\mu_{i}$. Independence also holds for rewards across machines.\par

        Every round $K$, we can take a gambling machine to play and record its rewards. After several rounds, we can explore the machine with highest average rewards. We want to optimize the regret, $i.e.$ $$\mu^{*}n-\mu_j \sum\limits^{K}_{j=1}E[T_j(n)]\quad where \quad \mu^*= \max_{1 \le i \le K}\mu_i$$

        Now we are given some prior knowledge about the arms(may be inaccurate), in the form of their estimated mean values $\tilde{\mu} = (\tilde{\mu_{1}},\cdots, \tilde{\mu_N})$. Based on these, we build new upper confidence bound.

    \end{subsection}

    \begin{subsection}{Analysis}
        Due to prior knowledge, we consider the multi-armed bandit model from a Bayesian point of view and a prior distribution. Therefore, we focus on the most important distribution which is one-parameter exponential family, one assumes that the parameter $\theta = (\theta_1,...,\theta_k)$ is drawn from a prior distribution.\\ \par

        [Distribution]: 
         $P = \{\nu_\theta,\theta \in \Theta:\nu_\theta$ has a density $f_\theta(x)=exp(\theta x-b(\theta))$ w.r.t $\xi\}$
        where $\Theta = (\theta^-,\theta^+)\subset R$ is an open interval, b a twice-differentiable and convex function(called the log-partition function) and $\xi$ a reference measure. As we all know, if $X\sim \nu_\theta$, it can be shown that E[X]=$\dot b(\theta)$ and Var[X]=$\ddot b(\theta)>0 $, where $\dot b(resp. \ddot b)$ is the derivative(resp. second derivative) of b with respect to the natural parameter $\theta$.\\ \par

        At first, we will focus on Bernoulli distribution because it maximizes deviations among bounded variables with given expectation. As we all know, $H=-\sum\limits_M P_MlnP_M$, we have maximum entropy distribution $P_M = \frac{1}{Z(\lambda)}exp\{\lambda r(M)\} $, where $Z(\lambda) = \sum\limits exp\{\lambda r(M)\}$. From this formula we know that the maximum entropy distribution is $P_M = p^r(1-p)^{n-r} $. Then we will focus on one-parameter exponential family.\\ \par 

        [Prior \&  Posterior Distributions]:
        For different conditional distribution, we usually take different conjugate priors. For example, if the distribution is Bernoulli distribution $B(\mu)$， we will take Beta distribution as our prior distribution Beta(a,b) and the posterior distribution is Beta(a+nx,b+n(1-x)), where n is the number of observations and x is empirical mean.\\ \par

        [Confidence Interval]:
        We need to build up an upper confidence bound, so I use the notation that $Q(\alpha,\pi)$ is the quantile of order $\alpha$ of the distribution $\pi$. And we need to find the order $\alpha$. For traditional UCB1 algorithm, the order is $1-\frac{1}{t}$, and we can make some change to improve the performance. We also have $KL(\nu_\theta,\nu_\lambda)=\dot b(\theta)(\theta-\lambda)-b(\theta)+b(\lambda)$, to simplify our notation, we introduce the KL-divergence between the distributions of mean $\mu$ and $\mu'$ : $$d(\mu,\mu'):=KL(\nu^\mu,\nu^{\mu'})=KL(\nu_{\dot b^{-1}(\mu)},\nu_{\dot b^{-1}(\mu')})$$


    \end{subsection}


    \begin{subsection}{Assumption}
        \begin{itemize}
          \item The joint distribution of $X_{i,t}$ is stationary, which means the distribution will not vary due to the choice of players and time. (Due to this assumption, I can use regret as our performance standard)
          \item  $X_{i,1},X_{i,2},\cdots$are i.i.d. and independence also holds for rewards across machines. (To simplify the problem, I want to see the simplest situation)
          \item We assume the distribution of all k machings subject to one-parameter canonical exponential family.  (Because the general condition is too hard for me to analyze, I want to design an algorithm for the most important case)
        \end{itemize}
    
    \end{subsection}

    \begin{algorithm}[htb]  
      \caption{Bayes-UCB}  
      \label{alg:Bayes-UCB}  
      \begin{algorithmic}[1]  
        \Require  
          $\Pi^0$ (The initial prior on $\theta$);
          $c$ (parameters of the quantile); 
          $n$ (horizon);  
    %        \Ensure  Ensemble of classifiers on the current batch, $E_n$;  
        \State for $t=1$ to $n$ do  
        \State \quad for each arm j=1,...,K do
        \State \quad \quad compute 
        \State \quad \quad \quad $q_j(t)=Q(1-\frac{1}{t(\log t)^c},\pi_j^{t-1})$
        \State \quad end for 
        \State \quad draw arm $I_t=arg \max_{j=1...K}q_j(t)$ 
        \State \quad get reward $Y_t=X_{I_t,t}$ and update $\Pi^t$ according to $\pi^t_j(\theta_j)\propto \nu_{\theta_j}(Y_t)\pi_j^{t-1}(\theta_j) $
        \State end for
      \end{algorithmic}  
    \end{algorithm}  

    \begin{subsection}{Performance}
    \newtheorem{theorem}{Theorem}[section]
    \newtheorem{lemma}[theorem]{Lemma}
        We assume that the rewards have a Bernoulli distribution, and when the prior is the Beta(1, 1), or uniform, law. We have the following theorem. We show that the Bayes- UCB algorithm is optimal, in the sense that it reaches the lower-bound of Lai and Robbins.
        \begin{theorem}{(Bernoulli Case)}
          For any $\epsilon>0$, choosing the parameter $c\ge 5$ in the Bayes-UCB algorithm, the number of draws of any sub-optimal arm j is upper-bounded by $$E[T_j(n)]\le \frac{1+\epsilon}{d(\mu_j,\mu^*)}log(n)+o_{\epsilon,c}(log(n))$$
        \end{theorem}
        \emph{Proof}: Proof is considered in \cite{Kaufmann2012On}.

        Then we consider that the rewards have a one-parameter canonical exponential family. This index policy is also asympotically optimal which reaches the lower-bound of Lai and Robbins. 

        \begin{lemma}
         For exponential family function, we have such inequality:\\
         1. There exists two positive constants A and B such that for all x,v that satisfy $\mu_0- < x <v <\mu_0+ $,for all $n \ge 1$ ,for all $a\in \{1,\cdots,K\}$,
         $$\frac{A}{n}e^{-nd(x,v)} \le P(\nu<X\le\mu^+) \le B \sqrt n e^{-nd(x,\nu)}$$
         2. There exists C such that for all x,v that satisfy $\mu_0- < x <v <\mu_0+ $,for all $n \ge 1$ ,for all $a\in \{1,\cdots,K\}$,
         $$P(\nu<X\le\mu^+)\ge \frac{C}{\sqrt n}$$
        \end{lemma}
        \emph{Proof}: Proof is considered in \cite{Kaufmann2016On}.

        \begin{theorem}{(One-parameter canonical exponential family Case)}
  			Let $\nu^\mu$ be an exponential bandit model. Assume that for all a, $\pi_a^0$ has a density $f_a$ w.r.t the Lebesgue measure such that $f_a(u)>0$ for all $u \in J=\dot b(\Theta)$. Let $\epsilon >0$, the algorithm that draws each arm once and for $t \ge K$ selects at time t+1 $$A_{t+1}=arg\max_{a}q_a(t)$$ , which satisfies
  			$$\forall a \not= a^*,\quad E[T_a(n)]\le \frac{1+\epsilon}{d(\mu_a,\mu^*)}log(n)+o_\epsilon(log(n)) $$
        \end{theorem}

        \emph{Proof}: Without losing generality, we assume arm 1 to be optimal and arm a to be a suboptimal arm. $$E[T_a(n)]=E[\sum\limits^{n-1}_{t=0} 1_{(A_{t+1}=a)}]
        	  \quad  \hat \mu_a(t)=(X_{a,1}+X_{a,2}+\cdots+X_{a,s})/s=\hat \mu_{a,T_a(t)} $$
        	   When we play a at round t+1, the condition must be $q_a(t)\ge q_1(t)$ , we have $$E(T_a(n))\le \sum\limits^{n-1}_{t=0}P(\mu_1 - g_t\ge q_1(t))+\sum\limits^{n-1}_{t=0}P(\mu_1-g_t\le q_a(t),A_{t+1}=a)$$, where $g_t$ is decreasing sequence and the composition is used by the one used for KL-UCB.\cite{Garivier2013The}\\

        	   For the first term, due to the lower bound in lemma $$\{\mu_1-g_t \ge q_1(t)\} = \{F_{\pi_1}(\mu_1-g_t) \le 1-\frac{1}{tlog^ct}\} \subseteq \{\frac{Ae^{-T_1(t)}d(\hat\mu_1,\mu_1-g_t)}{T_1(t)}\le \frac{1}{tlog^c(t)}\}$$

        	   For the second term, due to the upper bound in lemma $$\{\mu_1-g_t\le q_a(t),A_{t+1}=a\}=\{P(\mu_1-g_t<\hat \mu_a\le\mu^+)\ge \frac{1}{tlog^ct},A_{t+1}=a \}$$
        	   $$\subseteq\{B \sqrt{ T_a(t)} e^{-T_a(t)d(\hat \mu_a, \mu_1-g_t)}\ge \frac{1}{tlog^ct},A_{t+1}=a\}$$

        	   Let's sum such two terms, from which we can see the first term is the order of o(log(n)) and the second term is the order of log(n).

        	   For the first term, $\sum\limits^{n-1}_{t=0}P(T_1(t)d(\hat\mu_1(t),\mu_1-g_t)\ge log(\frac{Atlog^ct}{T_1(t)})) $ from \cite{Kaufmann2016On} lemma 5, we know that it's the order $o(log(n))$.\\

        	   For the second term, it's more complicate. $\sum\limits_{t=0}^{n-1} P(B \sqrt{ T_a(t)} e^{-T_a(t)d(\hat \mu_a, \mu_1-g_t)}\ge \frac{1}{tlog^ct},A_{t+1}=a)\le \sum\limits_{t=0}^{n-1} \sum\limits^{t}_{s=1}P(B \sqrt{ T_a(t)} e^{-T_a(t)d(\hat \mu_a, \mu_1-g_t)}\ge \frac{1}{tlog^ct},A_{t+1}=a,T_a(t)=s) \le \sum\limits^{n}_{s=1}P(sd(\hat\mu_{a,s}, \mu_1-g_s)\le logn+cloglogn+log(B)+\frac{1}{2}logs) $ from \cite{Kaufmann2016On} lemma 6, we know that it's the order $log(n)+o(log(n)$

        	   From these two terms, we have conclusion that $E(T_a(n)) \sim log(n)$. Similar Proof is considered in \cite{Kaufmann2016On}
    \end{subsection}

    \begin{subsection}{Conclusion}
    	From the prior knowledge $\tilde{\mu} = (\tilde{\mu_{1}},\cdots, \tilde{\mu_N})$, we can construct prior distribution $\Pi^0$ with such mean. When we use the algorithm Bayes-UCB, we don't need to test each gambling machine once so that we can reduce K rounds. Then we will execute the algorithm to find upper confidence Bound and play the gambling machine with the highest rank. After that, we can update the posterior distribution and take another round. It's a well-proved algorithm which is suitable for such problem. So the proof is similar in~\cite{Kaufmann2016On} with some different details. 
    \end{subsection}
 \end{section}


\begin{section}{Problem2 Bike sharing economy}
	 \begin{subsection}{Analysis} 
	 \label{sub:name}
	 	We apply game theory framework to such problems. Different from previous model like Cournot Model and Bertrand Model, different companies offer different platforms with network effect, which are different products. Actually sharing bicycle martket is not a two-side market, it's a rental market with network externality instead. Its mode is called B2C(business to customer) unlike Uber which is a typical C2C company.

	 	First of all, we will analyze the action of each company respectively according to the Nash equilibrium. Then we will analyze the benefit of sharing.
	 \end{subsection}
	 
	 \begin{subsection}{Model and Assumption}
	 	\emph{Problem Description}: For Producers, We assume that there are K companies，each of which offers $N_i$ sharing bike (i=1,...K). Each company will require deposits and go after maximum profits.
	 	For consumers, in this problem, we assume that consumers' decision can be divided into two phases. First, they would choose a platform to pay for its deposit according to the total number of bicycles per person. Then they will rent bicycle depends on its price. The reason why we can divide the decision into two phases is that due to competition, the price among different companies remains the same so that they can attract consumers equally.

	 	\subsubsection{Modeling for Producers}
	 		There are K companies, each of which offers $N_i$ sharing bike (i=1,...K).Profits ($\pi_j$) follow such formula: $\pi_j=p\times q_j - c_j/T_j\times N_j$,where p means the income per time per bicycle，$T_j$ is average life of the bike,$c_i$ is the cost of each bicycle and $q_j$ means the number of customers who choose bicycles provided by this company.\\
	 		\emph{Assumption:}
	 			\begin{itemize}
	 				\item We assume that each company offer sharing bicycle with the same price $p$. Due to people's sensitiveness to price and low cost of changing platform, any bicycle with higher price will lose its consumers. 
	 				\item We assume that the cost includes fixed costs, production costs and their maintenance costs. The cost function has such formula: $c(N_j)= c_jN_j$, because I think that the margin cost must remain the same for sharing bike.
	 				\item The bicycles are all the same. 
	 			\end{itemize}  
	 	\subsubsection{Modeling for Consumers}
	 		For consumers, we need two-phase decision. For the first phase, we assume that $q_j \propto N_j$. Actual it means that everyone have the same opportunities to use sharing bicycle. So $\forall j,q_j/N_j=\lambda$, where $\lambda$ means that $\lambda$ persons use one bicycle per unit time. For the second phase, we assume linear demand function.\\
	 		\emph{Assumption:}
	 			\begin{itemize}
	 				\item we assume the first phase, $q_j = \lambda N_j$
	 				\item we assume linear demand function $q=\sum\limits q_j=A-Bp$
	 			\end{itemize}  
	 	\subsubsection{Modeling for Market}
	 		We assume that the market is perfect information because they can estimate the demand function roughly.
	 		\emph{Assumption:}
	 			\begin{itemize}
	 				\item there are no transaction costs and friction in such markets.
	 				\item Every company will estimate the demand function correctly and know other companies' yields of bicycles.
	 			\end{itemize}
	 \end{subsection}

	 \begin{subsection}{An naive Analysis}
	 	We list following equations:
	 	\begin{align}
	 		max(\pi_j) &= max(pq_j-\frac{c_j}{T_j}N_j)   \\ 
	 		s.t. \quad q_j   &= \lambda N_j\\
	 			\sum\limits q_j &=A - Bp
	 	\end{align}
	 	And we will get a quadratic response function.
	 	\begin{align}
	 		max(\pi_j)&=max\{\frac{-\lambda^2 N_j^2}{B}+(\frac{A}{B}\lambda -\frac{c_j}{T_j}-\frac{\lambda^2 \sum\limits_{i\not=j}N_i }{B})N_j\} \\
	 		N_j &= \frac{A \lambda-B c_j/T_j-\lambda^2 \sum\limits_{i\not=j}N_i}{2\lambda^2}
	 	\end{align}
	 	It reaches Nash Equilibrium. We take sum for 1 to K.
	 	\begin{align}
	 		N = \sum\limits^k_{j=1} N_j = \dfrac{AK \lambda-B\sum_j (c_j/T_j)}{\lambda^2\times(K+1)}
	 	\end{align}
	 \end{subsection}

	 \begin{subsection}{Analysis with Platform effect}
	 	The difference for platform effect is that $\lambda$ is not a constant, but a increasing function with $N_j$
	 	We list following equations:
	 	\begin{align}
	 		max(\pi_j) &= max(pq_j-\frac{c_j}{T_j}N_j)   \\ 
	 		s.t. \quad q_j   &= \lambda(N_j) N_j\\
	 			\sum\limits q_j &=A - Bp
	 	\end{align}
	 	And we will get a response function.

    \begin{align}
      \max(\pi_j) &= \max\{ - \frac{\lambda(N_j)^2 N_j^2}{B}+(\frac{A}{B}\lambda(N_j) -\frac{c_j}{T_j}-\frac{\lambda (N_j)^2 \sum\limits_{i\not=j}N_i }{B})N_j \} \\
      take \quad \lambda(N_j) &= \lambda N_j^{\alpha}, \alpha\in [0,1)\\
      0 &= (2+2\alpha)\lambda N_j^{2\alpha+1}+\lambda(2\alpha+1)(\sum\limits_{i\not=j}N_i)N_j^{2\alpha}-A\lambda(1+\alpha)N_j^\alpha+\frac{c_j}{T_j}B
    \end{align}

	 \end{subsection}

	 \begin{subsection}{The benefit of sharing}
    We assume that the number of person who want to buy bicycles is $T$, $T =\mu(N) \sum\limits_j \lambda_j N_j$. $\mu$ means that the ratio of the persons who buy bicycles to the total persons who rent bicycles and it will decrease if N increases because people would like to rent bicycles instead of purchasing bicycles with the increasing number of total sharing bicycles. \\ \par

    \emph{Assumption:} $N\uparrow \mu(N)\downarrow$ ,$N \mu(N)\uparrow$\\ \par

	 	We define benefits $G=\sum\limits_{j=1}^k (\mu(N)\lambda(N_j)N_j)/rate-N_j$, where rate means the average ratio of utility time to total time if anyone buy a bicycle.\\ \par 

    In such naive models, $G =\dfrac{AK \lambda-B\sum_j (c_j/T_j)}{\lambda^2\times(K+1)}(\mu(N)\lambda /rate-1)$. From this model, we can get some intuitive insights. First of all, if $K \to \infty$, $G\to \frac{A}{\lambda}(\mu(N)\lambda/rate - 1)$, given appropriate parameter, the benefits from sharing bicycles will approximately be a value with K. It means that with the competition increasing, N will increase. However, the change of benefits depend on the formula of $\mu(N)$ . Generally, the benefits will increase first and then decrease with K increasing. To sum up, it means that appropriate competition will increase the benefits while excessive competition will decrease the benefits.\\ \par

    With such platforms, we calculate (12). $G = \sum\limits_{j=1}^k\mu(N)\lambda N_j^{1+\alpha}/rate-N_j$. We can get numerical results by setting parameters reasonably. But we focus on the competition K. If k increase, we know that N will increase. There will be a dilemma between $\mu(N)$ and $N^{1+\alpha}$. With more data, I think I can further my research by numerical simulation.

	 \end{subsection}
 \end{section}
%----------------------------------------------------------------------------------------
%	CITATION SECTION
%----------------------------------------------------------------------------------------
\bibliography{a}
\bibliographystyle{plain}
\nocite{Czarnecki2015}
\nocite{Auer2002Finite}


\end{document}